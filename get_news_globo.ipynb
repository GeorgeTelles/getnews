{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPse+bQoBM1QaPjKPmEo/0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeTelles/getnews/blob/main/get_news_globo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News Extraction - Globo.com\n",
        "\n",
        "This project is a Python application that performs news extraction from the main page of the Globo.com website. The goal is to capture the titles and links of the highlighted news articles on the homepage and display them in an organized manner.\n",
        "\n",
        "## Functionality\n",
        "\n",
        "The Python script performs the following tasks:\n",
        "\n",
        "1. **HTTP Request**: Uses the `requests` library to send an HTTP GET request to the main page of the Globo.com website.\n",
        "2. **HTML Parsing**: Parses the HTML content of the page using the `BeautifulSoup` library from `bs4`.\n",
        "3. **Data Extraction**: Searches for all `<a>` elements on the page and filters those containing news titles, identifying them by their specific CSS classes.\n",
        "4. **Dictionary Creation**: Stores the news titles and their corresponding links in a dictionary.\n",
        "5. **Display**: Prints the titles and links of the news articles in a readable format in the console.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Python 3.x\n",
        "- Libraries: `requests`, `beautifulsoup4`\n"
      ],
      "metadata": {
        "id": "BsWgcUxnjS7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "7X5Gi838isV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvggsrN8iVve"
      },
      "outputs": [],
      "source": [
        "def get_news():\n",
        "    url = \"https://www.globo.com/\"\n",
        "\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.text, \"html.parser\" )\n",
        "\n",
        "    noticias = soup.find_all(\"a\")\n",
        "\n",
        "    tgt_class1 = \"post__title\"\n",
        "    tgt_class2 = \"post-multicontent__link--title__text\"\n",
        "\n",
        "    news_dict = {}\n",
        "\n",
        "    for noticia in noticias:\n",
        "        if(noticia.h2 != None) and (noticia.h2.get(\"class\") != None):\n",
        "            if tgt_class1 in noticia.h2.get(\"class\"):\n",
        "                news_dict[noticia.h2.text] = noticia.get(\"href\")\n",
        "            if tgt_class2 in noticia.h2.get(\"class\"):\n",
        "                news_dict[noticia.h2.text] = noticia.get(\"href\")\n",
        "    return  news_dict\n",
        "\n",
        "news = get_news()\n",
        "\n",
        "for chave, valor in news.items():\n",
        "    print(\"TÃ­tulo:\", chave)\n",
        "    print(\"Link:\", valor)\n",
        "    print(\"-\" * 30)"
      ]
    }
  ]
}